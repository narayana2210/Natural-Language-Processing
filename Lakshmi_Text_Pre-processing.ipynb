{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_0='Why is this $[...] when i\\'d the same product is won available for $[...] here?<br />http://www.amazon.com/VICTOR-FLY-MAGNET-BAIT-REFILL/dp/B00004RBDY<br /><br />The Victor M380 and M502 traps are unreal, of course -- total fly genocide. Pretty stinky, but fly only right nearby.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is this $[...] when i'd the same product is won available for $[...] here?<br />http://www.amazon.com/VICTOR-FLY-MAGNET-BAIT-REFILL/dp/B00004RBDY<br /><br />The Victor M380 and M502 traps are unreal, of course -- total fly genocide. Pretty stinky, but fly only right nearby.\n",
      "\n",
      " Why is this $[...] when i'd the same product is won available for $[...] here?<br /> /><br />The Victor M380 and M502 traps are unreal, of course -- total fly genocide. Pretty stinky, but fly only right nearby.\n"
     ]
    }
   ],
   "source": [
    "print(sent_0)\n",
    "# remove urls from text python: https://stackoverflow.com/a/40823105/4084039\n",
    "sent_0 = re.sub(r\"http\\S+\", \"\", sent_0)\n",
    "\n",
    "print(\"\\n\",sent_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is this $[...] when i'd the same product is won available for $[...] here? />The Victor M380 and M502 traps are unreal, of course -- total fly genocide. Pretty stinky, but fly only right nearby.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(sent_0, 'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is this $[...] when i would the same product is won available for $[...] here? />The Victor M380 and M502 traps are unreal, of course -- total fly genocide. Pretty stinky, but fly only right nearby.\n"
     ]
    }
   ],
   "source": [
    "text = decontracted(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is this $[...] when i would the same product is won available for $[...] here? />The Victor  and  traps are unreal, of course -- total fly genocide. Pretty stinky, but fly only right nearby.\n"
     ]
    }
   ],
   "source": [
    "#remove words with numbers python: https://stackoverflow.com/a/18082370/4084039\n",
    "sent_0 = re.sub(\"\\S*\\d\\S*\", \"\", text).strip()\n",
    "print(sent_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is this when i would the same product is won available for here The Victor and traps are unreal of course total fly genocide Pretty stinky but fly only right nearby \n"
     ]
    }
   ],
   "source": [
    "sent_0 = re.sub('[^A-Za-z0-9]+', ' ', sent_0)\n",
    "print(sent_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "tokens = parser(sent_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(sent_0)\n",
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []\n",
    "for tok in tokens:\n",
    "    lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traps\n"
     ]
    }
   ],
   "source": [
    "print(tokens[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naray\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretty', 'stinky', 'right', 'victor', 'traps', 'fly', 'available', 'nearby', 'product', 'total', 'course', 'genocide', 'unreal']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS))\n",
    "tokens = [tok for tok in tokens if tok.lower() not in STOPLIST]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fly', 'product', 'total', 'pretty', 'unreal', 'traps', 'course', 'stinky', 'right', 'genocide', 'victor', 'available', 'nearby']\n"
     ]
    }
   ],
   "source": [
    "tokens = list(set(tokens))\n",
    "    #return tokens\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product victor unreal genocide nearby traps course total available right stinky pretty fly'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(tokens[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#BoW\n",
    "count_vect = CountVectorizer() #in scikit-learn\n",
    "count_vect.fit(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "the shape of out text BOW vectorizer  (13, 13)\n",
      "the number of unique words  13\n"
     ]
    }
   ],
   "source": [
    "final_counts = count_vect.transform(tokens)\n",
    "print(\"the type of count vectorizer \",type(final_counts))\n",
    "print(\"the shape of out text BOW vectorizer \",final_counts.get_shape())\n",
    "print(\"the number of unique words \", final_counts.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some feature names  ['available', 'course', 'fly', 'genocide', 'nearby', 'pretty', 'product', 'right', 'stinky', 'total', 'traps', 'unreal', 'victor']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"some feature names \", count_vect.get_feature_names()[:100])\n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t1\n",
      "  (1, 12)\t1\n",
      "  (2, 11)\t1\n",
      "  (3, 3)\t1\n",
      "  (4, 4)\t1\n",
      "  (5, 10)\t1\n",
      "  (6, 1)\t1\n",
      "  (7, 9)\t1\n",
      "  (8, 0)\t1\n",
      "  (9, 7)\t1\n",
      "  (10, 8)\t1\n",
      "  (11, 5)\t1\n",
      "  (12, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "print(final_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
